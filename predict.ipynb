{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library for data manipulation\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NBA games dataset from CSV file\n",
    "df = pd.read_csv(\"nba_games.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort games by date to ensure chronological order for time series analysis\n",
    "df = df.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index after sorting to have clean sequential indices\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns that aren't needed for analysis\n",
    "del df[\"mp.1\"]\n",
    "del df[\"mp_opp.1\"]\n",
    "del df[\"index_opp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1531426621.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"team\", group_keys=False).apply(add_target)\n"
     ]
    }
   ],
   "source": [
    "# Create target variable: whether the team won their NEXT game\n",
    "# This shifts the \"won\" column by -1 for each team, so we're predicting future outcomes\n",
    "def add_target(group):\n",
    "    group[\"target\"] = group[\"won\"].shift(-1)\n",
    "    return group\n",
    "\n",
    "df = df.groupby(\"team\", group_keys=False).apply(add_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing target values (last game of each team's season)\n",
    "# Replace NaN values with 2 and convert target to integer type\n",
    "df.loc[pd.isnull(df[\"target\"]), \"target\"] = 2\n",
    "df[\"target\"] = df[\"target\"].astype(int, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with null/missing values\n",
    "nulls = pd.isnull(df).sum()\n",
    "nulls = nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of valid columns (those without any null values)\n",
    "valid_columns = df.columns[~df.columns.isin(nulls.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid columns (remove columns with missing values)\n",
    "df = df[valid_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns to exclude from model features\n",
    "# Remove metadata and target-related columns\n",
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with only the features needed for rolling averages\n",
    "df_rolling = df[list(selected_columns) + [\"won\", \"team\", \"season\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/3101926349.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)\n"
     ]
    }
   ],
   "source": [
    "# Calculate rolling averages for each team over their last 10 games\n",
    "# This captures recent team performance trends\n",
    "def find_team_averages(team):\n",
    "    # Only calculate rolling for numeric columns\n",
    "    numeric_cols = team[selected_columns].select_dtypes(include=['number']).columns\n",
    "    rolling = team[numeric_cols].rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EWM features dataframe\n",
    "df_ewm = df[list(selected_columns) + [\"won\", \"team\", \"season\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_37923/1087153977.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_ewm = df_ewm.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_ewm)\n"
     ]
    }
   ],
   "source": [
    "# Calculate exponentially weighted moving averages\n",
    "# Recent games are weighted MORE heavily than older games\n",
    "def find_team_ewm(team):\n",
    "    # Only calculate EWM for numeric columns\n",
    "    numeric_cols = team[selected_columns].select_dtypes(include=['number']).columns\n",
    "    ewm = team[numeric_cols].ewm(span=10, adjust=False).mean()\n",
    "    return ewm\n",
    "\n",
    "df_ewm = df_ewm.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_ewm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename EWM columns with _ewm suffix\n",
    "ewm_cols = [f\"{col}_ewm\" for col in df_ewm.columns]\n",
    "df_ewm.columns = ewm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate rolling and EWM features to main dataframe\n",
    "df = pd.concat([df, df_rolling, df_ewm], axis=1)\n",
    "\n",
    "# Remove duplicate columns created by concat\n",
    "df = df.loc[:, ~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by team and date\n",
    "df = df.sort_values([\"team\", \"date\"])\n",
    "\n",
    "# Add next game columns using simple groupby shift\n",
    "df[\"home_next\"] = df.groupby(\"team\")[\"home\"].shift(-1)\n",
    "df[\"team_opp_next\"] = df.groupby(\"team\")[\"team_opp\"].shift(-1)\n",
    "df[\"date_next\"] = df.groupby(\"team\")[\"date\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual column names for rolling and EWM features\n",
    "rolling_cols = [col for col in df.columns if col.endswith('_10')]\n",
    "ewm_cols = [col for col in df.columns if col.endswith('_ewm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to create full dataset with both team's and opponent's features\n",
    "full = df.merge(\n",
    "  df[rolling_cols + ewm_cols + [\"team_opp_next\", \"date_next\", \"team\"]], \n",
    "  left_on=[\"team\", \"date_next\"], \n",
    "  right_on=[\"team_opp_next\", \"date_next\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to remove (metadata and text columns)\n",
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + removed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric feature columns only\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 161 227 294 360] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectKBest(k=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SelectKBest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.SelectKBest.html\">?<span>Documentation for SelectKBest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SelectKBest(k=50)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SelectKBest(k=50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SelectKBest for fast feature selection (takes seconds instead of hours)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=50)\n",
    "selector.fit(full[selected_columns], full[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 50 features\n"
     ]
    }
   ],
   "source": [
    "# Get the selected features\n",
    "predictors = list(selected_columns[selector.get_support()])\n",
    "print(f\"Selected {len(predictors)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting function: simulates real-world predictions over time\n",
    "# Trains on past seasons and predicts future seasons\n",
    "def backtest(data, model, predictors, start=2, step=1):\n",
    "    all_predictions = []\n",
    "    \n",
    "    seasons = sorted(data[\"season\"].unique())\n",
    "    \n",
    "    # Loop through seasons, train on past data, test on current season\n",
    "    for i in range(start, len(seasons), step):\n",
    "        season = seasons[i]\n",
    "        train = data[data[\"season\"] < season]\n",
    "        test = data[data[\"season\"] == season]\n",
    "        \n",
    "        model.fit(train[predictors], train[\"target\"])\n",
    "        \n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds, index=test.index)\n",
    "        combined = pd.concat([test[\"target\"], preds], axis=1)\n",
    "        combined.columns = [\"actual\", \"prediction\"]\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ridge Classifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest with Ridge Classifier\n",
    "predictions = backtest(full, rr, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Accuracy: 0.6560 (65.60%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Ridge Classifier accuracy\n",
    "ridge_accuracy = accuracy_score(predictions[\"actual\"], predictions[\"prediction\"])\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy:.4f} ({ridge_accuracy * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_MAP = {\n",
    "    'Atlanta Hawks': 'ATL', 'Boston Celtics': 'BOS', 'Brooklyn Nets': 'BRK',\n",
    "    'Charlotte Hornets': 'CHO', 'Chicago Bulls': 'CHI', 'Cleveland Cavaliers': 'CLE',\n",
    "    'Dallas Mavericks': 'DAL', 'Denver Nuggets': 'DEN', 'Detroit Pistons': 'DET',\n",
    "    'Golden State Warriors': 'GSW', 'Houston Rockets': 'HOU', 'Indiana Pacers': 'IND',\n",
    "    'Los Angeles Clippers': 'LAC', 'Los Angeles Lakers': 'LAL', 'Memphis Grizzlies': 'MEM',\n",
    "    'Miami Heat': 'MIA', 'Milwaukee Bucks': 'MIL', 'Minnesota Timberwolves': 'MIN',\n",
    "    'New Orleans Pelicans': 'NOP', 'New York Knicks': 'NYK', 'Oklahoma City Thunder': 'OKC',\n",
    "    'Orlando Magic': 'ORL', 'Philadelphia 76ers': 'PHI', 'Phoenix Suns': 'PHO',\n",
    "    'Portland Trail Blazers': 'POR', 'Sacramento Kings': 'SAC', 'San Antonio Spurs': 'SAS',\n",
    "    'Toronto Raptors': 'TOR', 'Utah Jazz': 'UTA', 'Washington Wizards': 'WAS'\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, df, predictors, upcoming_file, team=None, n_games=3, append=True):\n",
    "    \"\"\"\n",
    "    Generate predictions for upcoming games.\n",
    "    Set append=True to add to existing predictions (default)\n",
    "    Set append=False to overwrite predictions file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load upcoming games\n",
    "    upcoming = pd.read_csv(upcoming_file)\n",
    "    upcoming['date'] = pd.to_datetime(upcoming['date'], format='mixed')\n",
    "    \n",
    "    # Map team names to abbreviations\n",
    "    upcoming['home_abbrev'] = upcoming['home'].map(TEAM_MAP)\n",
    "    upcoming['visitor_abbrev'] = upcoming['visitor'].map(TEAM_MAP)\n",
    "    \n",
    "    # Filter for specific team if requested\n",
    "    if team:\n",
    "        upcoming = upcoming[\n",
    "            (upcoming['home_abbrev'] == team) | \n",
    "            (upcoming['visitor_abbrev'] == team)\n",
    "        ]\n",
    "    \n",
    "    # Sort by date and get next n_games per team\n",
    "    upcoming = upcoming.sort_values('date')\n",
    "    \n",
    "    if team:\n",
    "        upcoming = upcoming.head(n_games)\n",
    "    else:\n",
    "        # Get next n_games for each team\n",
    "        games_list = []\n",
    "        for t in df['team'].unique():\n",
    "            team_games = upcoming[\n",
    "                (upcoming['home_abbrev'] == t) | \n",
    "                (upcoming['visitor_abbrev'] == t)\n",
    "            ].head(n_games)\n",
    "            games_list.append(team_games)\n",
    "        upcoming = pd.concat(games_list).drop_duplicates(subset=['date', 'home', 'visitor'])\n",
    "    \n",
    "    # Load existing predictions to avoid duplicates\n",
    "    existing_predictions = None\n",
    "    if append and os.path.exists('data/predictions.csv'):\n",
    "        existing_predictions = pd.read_csv('data/predictions.csv')\n",
    "        existing_predictions['date'] = pd.to_datetime(existing_predictions['date']).dt.strftime('%Y-%m-%d')\n",
    "        existing_keys = set(zip(existing_predictions['date'], existing_predictions['home'], existing_predictions['visitor']))\n",
    "    else:\n",
    "        existing_keys = set()\n",
    "    \n",
    "    # Get rolling/EWM columns\n",
    "    rolling_cols = [col for col in df.columns if col.endswith('_10')]\n",
    "    ewm_cols = [col for col in df.columns if col.endswith('_ewm')]\n",
    "    \n",
    "    # Get most recent stats for each team\n",
    "    df_sorted = df.sort_values(['team', 'date'])\n",
    "    latest_stats = df_sorted.groupby('team').last().reset_index()\n",
    "    \n",
    "    predictions_list = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for _, game in upcoming.iterrows():\n",
    "        home = game['home_abbrev']\n",
    "        visitor = game['visitor_abbrev']\n",
    "        game_date = game['date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Skip if already predicted\n",
    "        if (game_date, game['home'], game['visitor']) in existing_keys:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Get team stats\n",
    "        home_stats = latest_stats[latest_stats['team'] == home]\n",
    "        visitor_stats = latest_stats[latest_stats['team'] == visitor]\n",
    "        \n",
    "        if len(home_stats) == 0 or len(visitor_stats) == 0:\n",
    "            print(f\"Skipping {visitor} @ {home} - missing team data\")\n",
    "            continue\n",
    "        \n",
    "        # Build feature row\n",
    "        feature_row = {}\n",
    "        \n",
    "        for col in rolling_cols + ewm_cols:\n",
    "            if col in home_stats.columns:\n",
    "                feature_row[col] = home_stats[col].values[0]\n",
    "        \n",
    "        for col in rolling_cols + ewm_cols:\n",
    "            col_y = f\"{col}_y\"\n",
    "            if col in visitor_stats.columns and col_y in predictors:\n",
    "                feature_row[col_y] = visitor_stats[col].values[0]\n",
    "        \n",
    "        feature_row['home'] = 1\n",
    "        \n",
    "        pre_df = pd.DataFrame([feature_row])\n",
    "        \n",
    "        for col in predictors:\n",
    "            if col not in pre_df.columns:\n",
    "                pre_df[col] = 0\n",
    "        \n",
    "        pre_df = pre_df[predictors]\n",
    "        \n",
    "        pred = model.predict(pre_df)[0]\n",
    "        \n",
    "        if hasattr(model, 'decision_function'):\n",
    "            confidence = abs(model.decision_function(pre_df)[0])\n",
    "        else:\n",
    "            confidence = None\n",
    "        \n",
    "        predictions_list.append({\n",
    "            'date': game_date,\n",
    "            'home': game['home'],\n",
    "            'home_abbrev': home,\n",
    "            'visitor': game['visitor'],\n",
    "            'visitor_abbrev': visitor,\n",
    "            'predicted_winner': game['home'] if pred == 1 else game['visitor'],\n",
    "            'predicted_winner_abbrev': home if pred == 1 else visitor,\n",
    "            'confidence': confidence,\n",
    "            'result': 'not_played'\n",
    "        })\n",
    "    \n",
    "    # Combine with existing predictions\n",
    "    new_predictions = pd.DataFrame(predictions_list)\n",
    "    \n",
    "    if append and existing_predictions is not None:\n",
    "        predictions_df = pd.concat([existing_predictions, new_predictions], ignore_index=True)\n",
    "    else:\n",
    "        predictions_df = new_predictions\n",
    "    \n",
    "    # Save\n",
    "    predictions_df.to_csv('data/predictions.csv', index=False)\n",
    "    print(f\"Added {len(predictions_list)} new predictions (skipped {skipped} existing)\")\n",
    "    print(f\"Total predictions: {len(predictions_df)}\")\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 22 new predictions (skipped 26 existing)\n",
      "Total predictions: 72\n",
      "======================================================================\n",
      "UPCOMING GAME PREDICTIONS\n",
      "======================================================================\n",
      "2026-01-17  OKC @ MIA  -->  MIA wins\n",
      "2026-01-19  OKC @ CLE  -->  CLE wins\n",
      "2026-01-21  OKC @ MIL  -->  MIL wins\n",
      "2026-01-19  MIL @ ATL  -->  ATL wins\n",
      "2026-01-21  ATL @ MEM  -->  MEM wins\n",
      "2026-01-23  PHO @ ATL  -->  ATL wins\n",
      "2026-01-19  BOS @ DET  -->  DET wins\n",
      "2026-01-21  IND @ BOS  -->  BOS wins\n",
      "2026-01-23  BOS @ BRK  -->  BRK wins\n",
      "2026-01-19  PHO @ BRK  -->  BRK wins\n",
      "2026-01-21  BRK @ NYK  -->  NYK wins\n",
      "2026-01-20  LAC @ CHI  -->  CHI wins\n",
      "2026-01-22  CHI @ MIN  -->  MIN wins\n",
      "2026-01-24  BOS @ CHI  -->  CHI wins\n",
      "2026-01-21  CLE @ CHO  -->  CHO wins\n",
      "2026-01-22  CHO @ ORL  -->  ORL wins\n",
      "2026-01-24  WAS @ CHO  -->  CHO wins\n",
      "2026-01-23  SAC @ CLE  -->  CLE wins\n",
      "2026-01-19  DAL @ NYK  -->  NYK wins\n",
      "2026-01-22  GSW @ DAL  -->  DAL wins\n",
      "2026-01-24  LAL @ DAL  -->  DAL wins\n",
      "2026-01-20  LAL @ DEN  -->  DEN wins\n",
      "2026-01-22  DEN @ WAS  -->  WAS wins\n",
      "2026-01-23  DEN @ MIL  -->  MIL wins\n",
      "2026-01-21  DET @ NOP  -->  NOP wins\n",
      "2026-01-23  HOU @ DET  -->  DET wins\n",
      "2026-01-19  MIA @ GSW  -->  GSW wins\n",
      "2026-01-20  TOR @ GSW  -->  GSW wins\n",
      "2026-01-20  SAS @ HOU  -->  HOU wins\n",
      "2026-01-22  HOU @ PHI  -->  PHI wins\n",
      "2026-01-19  IND @ PHI  -->  PHI wins\n",
      "2026-01-23  IND @ OKC  -->  OKC wins\n",
      "2026-01-19  LAC @ WAS  -->  WAS wins\n",
      "2026-01-22  LAL @ LAC  -->  LAC wins\n",
      "2026-01-23  NOP @ MEM  -->  MEM wins\n",
      "2026-01-25  DEN @ MEM  -->  MEM wins\n",
      "2026-01-20  MIA @ SAC  -->  SAC wins\n",
      "2026-01-22  MIA @ POR  -->  POR wins\n",
      "2026-01-20  MIN @ UTA  -->  UTA wins\n",
      "2026-01-24  GSW @ MIN  -->  MIN wins\n",
      "2026-01-25  NOP @ SAS  -->  SAS wins\n",
      "2026-01-24  NYK @ PHI  -->  PHI wins\n",
      "2026-01-24  CLE @ ORL  -->  ORL wins\n",
      "2026-01-26  ORL @ CLE  -->  CLE wins\n",
      "2026-01-20  PHO @ PHI  -->  PHI wins\n",
      "2026-01-23  TOR @ POR  -->  POR wins\n",
      "2026-01-26  POR @ BOS  -->  BOS wins\n",
      "2026-01-21  TOR @ SAC  -->  SAC wins\n",
      "2026-01-19  UTA @ SAS  -->  SAS wins\n",
      "2026-01-22  SAS @ UTA  -->  UTA wins\n",
      "2026-01-26  IND @ ATL  -->  ATL wins\n",
      "2026-01-28  ATL @ BOS  -->  BOS wins\n",
      "2026-01-25  BRK @ LAC  -->  LAC wins\n",
      "2026-01-27  BRK @ PHO  -->  PHO wins\n",
      "2026-01-26  LAL @ CHI  -->  CHI wins\n",
      "2026-01-26  PHI @ CHO  -->  CHO wins\n",
      "2026-01-25  DAL @ MIL  -->  MIL wins\n",
      "2026-01-25  SAC @ DET  -->  DET wins\n",
      "2026-01-27  DET @ DEN  -->  DEN wins\n",
      "2026-01-26  GSW @ MIN  -->  MIN wins\n",
      "2026-01-26  MEM @ HOU  -->  HOU wins\n",
      "2026-01-28  CHI @ IND  -->  IND wins\n",
      "2026-01-27  LAC @ UTA  -->  UTA wins\n",
      "2026-01-24  MIA @ UTA  -->  UTA wins\n",
      "2026-01-25  MIA @ PHO  -->  PHO wins\n",
      "2026-01-27  MIL @ PHI  -->  PHI wins\n",
      "2026-01-27  NOP @ OKC  -->  OKC wins\n",
      "2026-01-27  SAC @ NYK  -->  NYK wins\n",
      "2026-01-28  NYK @ TOR  -->  TOR wins\n",
      "2026-01-25  TOR @ OKC  -->  OKC wins\n",
      "2026-01-28  SAS @ HOU  -->  HOU wins\n",
      "2026-01-27  POR @ WAS  -->  WAS wins\n",
      "======================================================================\n",
      "Total predictions: 72\n"
     ]
    }
   ],
   "source": [
    "#train the model on all data first\n",
    "rr.fit(full[predictors], full[\"target\"])\n",
    "\n",
    "#generate predictions for all teams (next 3 games each)\n",
    "all_predictions = generate_predictions(rr, df, predictors, 'data/upcoming_games_2026.csv', n_games=3)\n",
    "\n",
    "# Display predictions nicely\n",
    "print(\"=\" * 70)\n",
    "print(\"UPCOMING GAME PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "for _, row in all_predictions.iterrows():\n",
    "    print(f\"{row['date']}  {row['visitor_abbrev']} @ {row['home_abbrev']}  -->  {row['predicted_winner_abbrev']} wins\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total predictions: {len(all_predictions)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 new predictions (skipped 3 existing)\n",
      "Total predictions: 72\n",
      "          date                    home home_abbrev          visitor  \\\n",
      "27  2026-01-20   Golden State Warriors         GSW  Toronto Raptors   \n",
      "45  2026-01-23  Portland Trail Blazers         POR  Toronto Raptors   \n",
      "47  2026-01-21        Sacramento Kings         SAC  Toronto Raptors   \n",
      "68  2026-01-28         Toronto Raptors         TOR  New York Knicks   \n",
      "69  2026-01-25   Oklahoma City Thunder         OKC  Toronto Raptors   \n",
      "\n",
      "   visitor_abbrev        predicted_winner predicted_winner_abbrev  confidence  \\\n",
      "27            TOR   Golden State Warriors                     GSW   13.389666   \n",
      "45            TOR  Portland Trail Blazers                     POR   13.389666   \n",
      "47            TOR        Sacramento Kings                     SAC   13.389666   \n",
      "68            NYK         Toronto Raptors                     TOR   13.317857   \n",
      "69            TOR   Oklahoma City Thunder                     OKC   13.389666   \n",
      "\n",
      "        result    actual_winner  \n",
      "27   incorrect  Toronto Raptors  \n",
      "45  not_played              NaN  \n",
      "47   incorrect  Toronto Raptors  \n",
      "68  not_played              NaN  \n",
      "69  not_played              NaN  \n"
     ]
    }
   ],
   "source": [
    "# get predictions for a specific team\n",
    "team_predictions = generate_predictions(rr, df, predictors, 'data/upcoming_games_2026.csv', team='TOR', n_games=3)\n",
    "tor_only = team_predictions[\n",
    "    (team_predictions['home_abbrev'] == 'TOR') | \n",
    "    (team_predictions['visitor_abbrev'] == 'TOR')\n",
    "]\n",
    "print(tor_only)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
