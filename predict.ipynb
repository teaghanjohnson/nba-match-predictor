{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NBA games dataset from CSV file\n",
    "df = pd.read_csv(\"nba_games.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort games by date to ensure chronological order for time series analysis\n",
    "df = df.sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index after sorting to have clean sequential indices\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns that aren't needed for analysis\n",
    "del df[\"mp.1\"]\n",
    "del df[\"mp_opp.1\"]\n",
    "del df[\"index_opp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  group[\"target\"] = group[\"won\"].shift(-1)\n",
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1531426621.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"team\", group_keys=False).apply(add_target)\n"
     ]
    }
   ],
   "source": [
    "# Create target variable: whether the team won their NEXT game\n",
    "# This shifts the \"won\" column by -1 for each team, so we're predicting future outcomes\n",
    "def add_target(group):\n",
    "    group[\"target\"] = group[\"won\"].shift(-1)\n",
    "    return group\n",
    "\n",
    "df = df.groupby(\"team\", group_keys=False).apply(add_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing target values (last game of each team's season)\n",
    "# Replace NaN values with 2 and convert target to integer type\n",
    "df.loc[pd.isnull(df[\"target\"]), \"target\"] = 2\n",
    "df[\"target\"] = df[\"target\"].astype(int, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with null/missing values\n",
    "nulls = pd.isnull(df).sum()\n",
    "nulls = nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of valid columns (those without any null values)\n",
    "valid_columns = df.columns[~df.columns.isin(nulls.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only valid columns (remove columns with missing values)\n",
    "df = df[valid_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns to exclude from model features\n",
    "# Remove metadata and target-related columns\n",
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOMENTUM & QUALITY FEATURES\n",
    "\n",
    "df =  df.sort_values([\"team\", \"date\"])\n",
    "\n",
    "# rest days and back to backs\n",
    "df['date_dt'] = pd.to_datetime(df['date'], format='mixed')\n",
    "df['days_rest'] = df.groupby('team')['date_dt'].diff().dt.days.fillna(3)\n",
    "df['back_to_back'] = (df[\"days_rest\"] ==1).astype(int)\n",
    "df[\"b2b_away\"] = ((df['back_to_back'] == 1) & (df['home'] == 0)).astype(int)\n",
    "\n",
    "# season record (culmulative)\n",
    "df['season_wins'] = df.groupby(['team', 'season'])['won'].cumsum()\n",
    "df['season_games'] = df.groupby(['team', 'season']).cumcount() + 1\n",
    "df['season_win_pct'] = df['season_wins'] / df['season_games']\n",
    "\n",
    "#opponent win percentage (use map)\n",
    "opp_lookup = df.set_index(['team', df.index])['season_win_pct']\n",
    "df['opp_win_pct'] = df.apply(\n",
    "    lambda row: df.loc[\n",
    "        (df['team'] == row['team_opp']) & (df['season'] == row['season']) & (df.index <= row.name),\n",
    "        'season_win_pct'\n",
    "    ].iloc[-1] if len(df.loc[\n",
    "        (df['team'] == row['team_opp']) & (df['season'] == row['season']) & (df.index <= row.name)\n",
    "    ]) > 0 else 0.5,\n",
    "    axis=1\n",
    ")\n",
    "df['win_pct_diff'] = df['season_win_pct'] - df['opp_win_pct']\n",
    "#head to head record\n",
    "df = df.sort_values(['team', 'team_opp', 'date'])\n",
    "df['h2h_wins'] = df.groupby(['team', 'team_opp'])['won'].cumsum()\n",
    "df['h2h_games'] = df.groupby(['team', 'team_opp']).cumcount() + 1\n",
    "df['h2h_win_pct'] = df['h2h_wins'] / df['h2h_games']\n",
    "\n",
    "# win/loss streaks\n",
    "\n",
    "df = df.sort_values([\"team\", \"date\"])\n",
    "def calc_streak(won_series):\n",
    "    streak = []\n",
    "    current = 0\n",
    "    for w in won_series:\n",
    "        if w == 1 or w == True:\n",
    "            current = max(0, current) + 1\n",
    "        elif w == 0 or w == False:\n",
    "            current = min(0, current) - 1\n",
    "        streak.append(current)\n",
    "    return streak\n",
    "\n",
    "\n",
    "df = df.sort_values(['team', 'date']).reset_index(drop=True)\n",
    "streaks = []\n",
    "for team in df['team'].unique():\n",
    "    team_mask = df['team'] == team\n",
    "    team_won = df.loc[team_mask, 'won'].tolist()\n",
    "    streaks.extend(calc_streak(team_won))\n",
    "\n",
    "df['streak'] = streaks\n",
    "df['win_streak'] = df['streak'].clip(lower=0)\n",
    "df['losing_streak'] = (-df['streak']).clip(lower=0)\n",
    "df['hot_streak'] = (df['win_streak'] > 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with only the features needed for rolling averages\n",
    "df_rolling = df[list(selected_columns) + [\"won\", \"team\", \"season\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/3101926349.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)\n"
     ]
    }
   ],
   "source": [
    "# Calculate rolling averages for each team over their last 10 games\n",
    "# This captures recent team performance trends\n",
    "def find_team_averages(team):\n",
    "    # Only calculate rolling for numeric columns\n",
    "    numeric_cols = team[selected_columns].select_dtypes(include=['number']).columns\n",
    "    rolling = team[numeric_cols].rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EWM features dataframe\n",
    "df_ewm = df[list(selected_columns) + [\"won\", \"team\", \"season\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/097q2jgx0y38117lgk3j9nf40000gn/T/ipykernel_82256/1087153977.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_ewm = df_ewm.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_ewm)\n"
     ]
    }
   ],
   "source": [
    "# Calculate exponentially weighted moving averages\n",
    "# Recent games are weighted MORE heavily than older games\n",
    "def find_team_ewm(team):\n",
    "    # Only calculate EWM for numeric columns\n",
    "    numeric_cols = team[selected_columns].select_dtypes(include=['number']).columns\n",
    "    ewm = team[numeric_cols].ewm(span=10, adjust=False).mean()\n",
    "    return ewm\n",
    "\n",
    "df_ewm = df_ewm.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_ewm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename EWM columns with _ewm suffix\n",
    "ewm_cols = [f\"{col}_ewm\" for col in df_ewm.columns]\n",
    "df_ewm.columns = ewm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate rolling and EWM features to main dataframe\n",
    "df = pd.concat([df, df_rolling, df_ewm], axis=1)\n",
    "\n",
    "# Remove duplicate columns created by concat\n",
    "df = df.loc[:, ~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by team and date\n",
    "df = df.sort_values([\"team\", \"date\"])\n",
    "\n",
    "# Add next game columns using simple groupby shift\n",
    "df[\"home_next\"] = df.groupby(\"team\")[\"home\"].shift(-1)\n",
    "df[\"team_opp_next\"] = df.groupby(\"team\")[\"team_opp\"].shift(-1)\n",
    "df[\"date_next\"] = df.groupby(\"team\")[\"date\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual column names for rolling and EWM features\n",
    "rolling_cols = [col for col in df.columns if col.endswith('_10')]\n",
    "ewm_cols = [col for col in df.columns if col.endswith('_ewm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['date_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to create full dataset with both team's and opponent's features\n",
    "full = df.merge(\n",
    "  df[rolling_cols + ewm_cols + [\"team_opp_next\", \"date_next\", \"team\"]], \n",
    "  left_on=[\"team\", \"date_next\"], \n",
    "  right_on=[\"team_opp_next\", \"date_next\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to remove (metadata and text columns)\n",
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + removed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric feature columns only\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectKBest(k=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SelectKBest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.SelectKBest.html\">?<span>Documentation for SelectKBest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SelectKBest(k=50)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SelectKBest(k=50)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SelectKBest for fast feature selection (takes seconds instead of hours)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(f_classif, k=50)\n",
    "selector.fit(full[selected_columns], full[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected features\n",
    "predictors = list(selected_columns[selector.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trains on past seasons and predicts future seasons\n",
    "def backtest(data, model, predictors, start=2, step=1):\n",
    "    all_predictions = []\n",
    "    seasons = sorted(data[\"season\"].unique())\n",
    "    \n",
    "    # loop through seasons, train on past data, test on current season\n",
    "    for i in range(start, len(seasons), step):\n",
    "        season = seasons[i]\n",
    "        train = data[data[\"season\"] < season]\n",
    "        test = data[data[\"season\"] == season]\n",
    "        \n",
    "        selector = SelectKBest(f_classif, k=50)\n",
    "        selector.fit(train[predictors], train[\"target\"])\n",
    "        selected = list(np.array(predictors)[selector.get_support()])\n",
    "\n",
    "        model.fit(train[selected], train[\"target\"])\n",
    "        preds = model.predict(test[selected])\n",
    "        preds = pd.Series(preds, index=test.index)\n",
    "        combined = pd.concat([test[\"target\"], preds], axis=1)\n",
    "        combined.columns = [\"actual\", \"prediction\"]\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ridge Classifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Run backtest with Ridge Classifier\n",
    "# Pass ALL candidate features (selected_columns), not pre-filtered predictors\n",
    "all_features = list(selected_columns)\n",
    "predictions = backtest(full, rr, all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Accuracy: 0.6602 (66.02%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Ridge Classifier accuracy\n",
    "ridge_accuracy = accuracy_score(predictions[\"actual\"], predictions[\"prediction\"])\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy:.4f} ({ridge_accuracy * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost Classifier with tuned hyperparameters\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=3,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 29  95 176 242 309 375] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Run backtest with XGBoost\n",
    "xgb_predictions = backtest(full, xgb, all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Accuracy: 0.6602 (66.02%)\n",
      "XGBoost Accuracy:          0.6528 (65.28%)\n",
      "Difference:                -0.73%\n"
     ]
    }
   ],
   "source": [
    "# Calculate XGBoost accuracy and compare\n",
    "xgb_accuracy = accuracy_score(xgb_predictions[\"actual\"], xgb_predictions[\"prediction\"])\n",
    "print(f\"Ridge Classifier Accuracy: {ridge_accuracy:.4f} ({ridge_accuracy * 100:.2f}%)\")\n",
    "print(f\"XGBoost Accuracy:          {xgb_accuracy:.4f} ({xgb_accuracy * 100:.2f}%)\")\n",
    "print(f\"Difference:                {(xgb_accuracy - ridge_accuracy) * 100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_MAP = {\n",
    "    'Atlanta Hawks': 'ATL', 'Boston Celtics': 'BOS', 'Brooklyn Nets': 'BRK',\n",
    "    'Charlotte Hornets': 'CHO', 'Chicago Bulls': 'CHI', 'Cleveland Cavaliers': 'CLE',\n",
    "    'Dallas Mavericks': 'DAL', 'Denver Nuggets': 'DEN', 'Detroit Pistons': 'DET',\n",
    "    'Golden State Warriors': 'GSW', 'Houston Rockets': 'HOU', 'Indiana Pacers': 'IND',\n",
    "    'Los Angeles Clippers': 'LAC', 'Los Angeles Lakers': 'LAL', 'Memphis Grizzlies': 'MEM',\n",
    "    'Miami Heat': 'MIA', 'Milwaukee Bucks': 'MIL', 'Minnesota Timberwolves': 'MIN',\n",
    "    'New Orleans Pelicans': 'NOP', 'New York Knicks': 'NYK', 'Oklahoma City Thunder': 'OKC',\n",
    "    'Orlando Magic': 'ORL', 'Philadelphia 76ers': 'PHI', 'Phoenix Suns': 'PHO',\n",
    "    'Portland Trail Blazers': 'POR', 'Sacramento Kings': 'SAC', 'San Antonio Spurs': 'SAS',\n",
    "    'Toronto Raptors': 'TOR', 'Utah Jazz': 'UTA', 'Washington Wizards': 'WAS'\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def archive_completed_predictions():\n",
    "    if not os.path.exists('data/predictions.csv'):\n",
    "        return\n",
    "    \n",
    "    predictions = pd.read_csv('data/predictions.csv')\n",
    "    \n",
    "    # Separate completed and upcoming\n",
    "    completed = predictions[predictions['result'] != 'not_played']\n",
    "    upcoming = predictions[predictions['result'] == 'not_played']\n",
    "    \n",
    "    if len(completed) > 0:\n",
    "        # Append completed to history\n",
    "        if os.path.exists('data/prediction_history.csv'):\n",
    "            history = pd.read_csv('data/prediction_history.csv')\n",
    "            history = pd.concat([history, completed], ignore_index=True)\n",
    "            # Remove duplicates based on date, home, visitor\n",
    "            history = history.drop_duplicates(subset=['date', 'home', 'visitor'], keep='last')\n",
    "        else:\n",
    "            history = completed\n",
    "        \n",
    "        history.to_csv('data/prediction_history.csv', index=False)\n",
    "        print(f\"Archived {len(completed)} completed predictions to history\")\n",
    "    \n",
    "    # Keep only upcoming in predictions.csv\n",
    "    upcoming.to_csv('data/predictions.csv', index=False)\n",
    "    return upcoming\n",
    "\n",
    "\n",
    "def generate_predictions(model, df, predictors, upcoming_file, team=None, n_games=3):\n",
    "\n",
    "    # first, archive any completed predictions\n",
    "    archive_completed_predictions()\n",
    "    \n",
    "    # load upcoming games\n",
    "    upcoming = pd.read_csv(upcoming_file)\n",
    "    upcoming['date'] = pd.to_datetime(upcoming['date'], format='mixed')\n",
    "    \n",
    "    # map team names to abbreviations\n",
    "    upcoming['home_abbrev'] = upcoming['home'].map(TEAM_MAP)\n",
    "    upcoming['visitor_abbrev'] = upcoming['visitor'].map(TEAM_MAP)\n",
    "    \n",
    "    # filter for specific team if requested\n",
    "    if team:\n",
    "        upcoming = upcoming[\n",
    "            (upcoming['home_abbrev'] == team) | \n",
    "            (upcoming['visitor_abbrev'] == team)\n",
    "        ]\n",
    "    \n",
    "    # sort by date and get next n_games per team\n",
    "    upcoming = upcoming.sort_values('date')\n",
    "    \n",
    "    if team:\n",
    "        upcoming = upcoming.head(n_games)\n",
    "    else:\n",
    "        # get next n_games for each team\n",
    "        games_list = []\n",
    "        for t in df['team'].unique():\n",
    "            team_games = upcoming[\n",
    "                (upcoming['home_abbrev'] == t) | \n",
    "                (upcoming['visitor_abbrev'] == t)\n",
    "            ].head(n_games)\n",
    "            games_list.append(team_games)\n",
    "        upcoming = pd.concat(games_list).drop_duplicates(subset=['date', 'home', 'visitor'])\n",
    "    \n",
    "    # load existing predictions to check what's already predicted\n",
    "    existing_keys = set()\n",
    "    if os.path.exists('data/predictions.csv'):\n",
    "        existing_predictions = pd.read_csv('data/predictions.csv')\n",
    "        if len(existing_predictions) > 0:\n",
    "            existing_predictions['date'] = pd.to_datetime(existing_predictions['date']).dt.strftime('%Y-%m-%d')\n",
    "            existing_keys = set(zip(existing_predictions['date'], existing_predictions['home'], existing_predictions['visitor']))\n",
    "    \n",
    "    # get rolling/EWM columns\n",
    "    rolling_cols = [col for col in df.columns if col.endswith('_10')]\n",
    "    ewm_cols = [col for col in df.columns if col.endswith('_ewm')]\n",
    "    \n",
    "    # get most recent stats for each team\n",
    "    df_sorted = df.sort_values(['team', 'date'])\n",
    "    latest_stats = df_sorted.groupby('team').last().reset_index()\n",
    "    \n",
    "    # separate predictors into home (_x or no suffix) and visitor (_y) features\n",
    "    home_predictors = [p for p in predictors if not p.endswith('_y')]\n",
    "    visitor_predictors = [p for p in predictors if p.endswith('_y')]\n",
    "    \n",
    "    predictions_list = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for _, game in upcoming.iterrows():\n",
    "        home = game['home_abbrev']\n",
    "        visitor = game['visitor_abbrev']\n",
    "        game_date = game['date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        # skip if already predicted\n",
    "        if (game_date, game['home'], game['visitor']) in existing_keys:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # get team stats\n",
    "        home_stats = latest_stats[latest_stats['team'] == home]\n",
    "        visitor_stats = latest_stats[latest_stats['team'] == visitor]\n",
    "        \n",
    "        if len(home_stats) == 0 or len(visitor_stats) == 0:\n",
    "            print(f\"Skipping {visitor} @ {home} - missing team data\")\n",
    "            continue\n",
    "        \n",
    "        # build feature row\n",
    "        feature_row = {}\n",
    "        \n",
    "        # match predictor columns to home team's stats\n",
    "        for col in home_predictors:\n",
    "            # try exact match first (e.g. 'home', 'season_win_pct')\n",
    "            if col in home_stats.columns:\n",
    "                feature_row[col] = home_stats[col].values[0]\n",
    "            # try without _x suffix (from merge)\n",
    "            elif col.endswith('_x') and col[:-2] in home_stats.columns:\n",
    "                feature_row[col] = home_stats[col[:-2]].values[0]\n",
    "        \n",
    "        # _y columns map to visitor's base stats\n",
    "        for col in visitor_predictors:\n",
    "            # strip _y suffix to find the base column name in visitor stats\n",
    "            base_col = col[:-2]  # remove '_y'\n",
    "            if base_col in visitor_stats.columns:\n",
    "                feature_row[col] = visitor_stats[base_col].values[0]\n",
    "        \n",
    "        pre_df = pd.DataFrame([feature_row])\n",
    "        \n",
    "        # fill any remaining missing predictors with 0\n",
    "        for col in predictors:\n",
    "            if col not in pre_df.columns:\n",
    "                pre_df[col] = 0\n",
    "        \n",
    "        pre_df = pre_df[predictors]\n",
    "        \n",
    "        pred = model.predict(pre_df)[0]\n",
    "        \n",
    "        # calculate confidence \n",
    "        if hasattr(model, 'decision_function'):\n",
    "            raw_score = abs(model.decision_function(pre_df)[0])\n",
    "            confidence = 1 / (1 + np.exp(-raw_score))  # maps to 0.5-1.0\n",
    "        else:\n",
    "            confidence = None\n",
    "        \n",
    "        predictions_list.append({\n",
    "            'date': game_date,\n",
    "            'home': game['home'],\n",
    "            'home_abbrev': home,\n",
    "            'visitor': game['visitor'],\n",
    "            'visitor_abbrev': visitor,\n",
    "            'predicted_winner': game['home'] if pred == 1 else game['visitor'],\n",
    "            'predicted_winner_abbrev': home if pred == 1 else visitor,\n",
    "            'confidence': confidence,\n",
    "            'result': 'not_played',\n",
    "            'actual_winner': ''\n",
    "        })\n",
    "    \n",
    "    # Combine with existing upcoming predictions\n",
    "    new_predictions = pd.DataFrame(predictions_list)\n",
    "    \n",
    "    if os.path.exists('data/predictions.csv'):\n",
    "        existing = pd.read_csv('data/predictions.csv')\n",
    "        if len(existing) > 0:\n",
    "            predictions_df = pd.concat([existing, new_predictions], ignore_index=True)\n",
    "        else:\n",
    "            predictions_df = new_predictions\n",
    "    else:\n",
    "        predictions_df = new_predictions\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    predictions_df = predictions_df.drop_duplicates(subset=['date', 'home', 'visitor'], keep='first')\n",
    "    predictions_df = predictions_df.sort_values('date')\n",
    "    \n",
    "    # Save only upcoming predictions\n",
    "    predictions_df.to_csv('data/predictions.csv', index=False)\n",
    "    print(f\"Added {len(predictions_list)} new predictions (skipped {skipped} existing)\")\n",
    "    print(f\"Total upcoming predictions: {len(predictions_df)}\")\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archived 44 completed predictions to history\n",
      "Added 43 new predictions (skipped 4 existing)\n",
      "Total upcoming predictions: 47\n",
      "======================================================================\n",
      "UPCOMING GAME PREDICTIONS\n",
      "======================================================================\n",
      "2026-02-19  BOS @ GSW  -->  BOS wins\n",
      "2026-02-19  TOR @ CHI  -->  TOR wins\n",
      "2026-02-19  DET @ NYK  -->  DET wins\n",
      "2026-02-19  ATL @ PHI  -->  ATL wins\n",
      "2026-02-19  IND @ WAS  -->  IND wins\n",
      "2026-02-19  ORL @ SAC  -->  SAC wins\n",
      "2026-02-19  BRK @ CLE  -->  CLE wins\n",
      "2026-02-19  DEN @ LAC  -->  LAC wins\n",
      "2026-02-19  PHO @ SAS  -->  SAS wins\n",
      "2026-02-19  HOU @ CHO  -->  HOU wins\n",
      "2026-02-20  UTA @ MEM  -->  MEM wins\n",
      "2026-02-20  LAC @ LAL  -->  LAL wins\n",
      "2026-02-20  IND @ WAS  -->  IND wins\n",
      "2026-02-20  DEN @ POR  -->  POR wins\n",
      "2026-02-20  DAL @ MIN  -->  DAL wins\n",
      "2026-02-20  MIL @ NOP  -->  MIL wins\n",
      "2026-02-20  BRK @ OKC  -->  OKC wins\n",
      "2026-02-20  MIA @ ATL  -->  ATL wins\n",
      "2026-02-20  CLE @ CHO  -->  CLE wins\n",
      "2026-02-21  HOU @ NYK  -->  HOU wins\n",
      "2026-02-21  MEM @ MIA  -->  MEM wins\n",
      "2026-02-21  PHI @ NOP  -->  PHI wins\n",
      "2026-02-21  DET @ CHI  -->  DET wins\n",
      "2026-02-21  SAC @ SAS  -->  SAS wins\n",
      "2026-02-21  ORL @ PHO  -->  PHO wins\n",
      "2026-02-22  ORL @ LAC  -->  LAC wins\n",
      "2026-02-22  BRK @ ATL  -->  ATL wins\n",
      "2026-02-22  CHO @ WAS  -->  WAS wins\n",
      "2026-02-22  POR @ PHO  -->  POR wins\n",
      "2026-02-22  DEN @ GSW  -->  DEN wins\n",
      "2026-02-22  NYK @ CHI  -->  NYK wins\n",
      "2026-02-22  DAL @ IND  -->  IND wins\n",
      "2026-02-22  PHI @ MIN  -->  MIN wins\n",
      "2026-02-22  CLE @ OKC  -->  OKC wins\n",
      "2026-02-22  BOS @ LAL  -->  LAL wins\n",
      "2026-02-22  TOR @ MIL  -->  MIL wins\n",
      "2026-02-23  SAS @ DET  -->  DET wins\n",
      "2026-02-23  SAC @ MEM  -->  SAC wins\n",
      "2026-02-23  UTA @ HOU  -->  HOU wins\n",
      "2026-02-24  MIN @ POR  -->  POR wins\n",
      "2026-02-24  ORL @ LAL  -->  LAL wins\n",
      "2026-02-24  OKC @ TOR  -->  OKC wins\n",
      "2026-02-24  GSW @ NOP  -->  GSW wins\n",
      "2026-02-24  DAL @ BRK  -->  DAL wins\n",
      "2026-02-24  BOS @ PHO  -->  BOS wins\n",
      "2026-02-24  MIA @ MIL  -->  MIL wins\n",
      "2026-02-26  NOP @ UTA  -->  UTA wins\n",
      "======================================================================\n",
      "Total predictions: 47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train the model on all data first\n",
    "rr.fit(full[predictors], full[\"target\"])\n",
    "\n",
    "#generate predictions for all teams (next 3 games each)\n",
    "all_predictions = generate_predictions(rr, df, predictors, 'data/upcoming_games_2026.csv', n_games=3)\n",
    "\n",
    "# Display predictions nicely\n",
    "print(\"=\" * 70)\n",
    "print(\"UPCOMING GAME PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "for _, row in all_predictions.iterrows():\n",
    "    print(f\"{row['date']}  {row['visitor_abbrev']} @ {row['home_abbrev']}  -->  {row['predicted_winner_abbrev']} wins\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total predictions: {len(all_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
